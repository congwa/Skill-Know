"""èŠå¤©æœåŠ¡

å®ç°åŸºäº Skill-driven çš„èŠå¤©åŠŸèƒ½ï¼Œæ”¯æŒæ¸è¿›å¼åŠ è½½å’Œæµå¼å“åº”ã€‚
"""

import asyncio
import time
import uuid
from collections.abc import AsyncGenerator
from typing import Any

from langchain_core.messages import HumanMessage, AIMessage
from sqlalchemy.ext.asyncio import AsyncSession

from langgraph_agent_kit import QueueDomainEmitter, make_event

from app.core.chat_models import V1ChatModel
from app.core.logging import get_logger
from app.schemas.events import StreamEventType, StreamEvent
from app.services.conversation import ConversationService
from app.services.skill import SkillService
from app.services.prompt import PromptService
from app.services.system_config import SystemConfigService
from app.services.agent.core import agent_service
from app.services.agent.streams import StreamingResponseHandler
from app.services.streaming.context import ChatContext

logger = get_logger("chat_service")


class ChatService:
    """èŠå¤©æœåŠ¡ - Skill-driven Agent"""

    def __init__(self, session: AsyncSession):
        self._session = session
        self._conversation_service = ConversationService(session)
        self._skill_service = SkillService(session)
        self._prompt_service = PromptService(session)
        self._config_service = SystemConfigService(session)

    async def _get_llm(self) -> V1ChatModel:
        """è·å– LLM å®ä¾‹ï¼ˆä½¿ç”¨ V1 æ¨¡å¼ï¼‰"""
        config = await self._config_service.get_llm_config()
        return V1ChatModel(
            api_key=config["api_key"],
            base_url=config["base_url"],
            model=config["chat_model"],
            streaming=True,
        )

    async def _build_messages(
        self,
        conversation_id: str,
        user_message: str,
        skill_context: str = "",
    ) -> list:
        """æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        
        Args:
            conversation_id: ä¼šè¯ ID
            user_message: ç”¨æˆ·æ¶ˆæ¯
            skill_context: åŒ¹é…çš„ Skill å†…å®¹ï¼ˆæ¸è¿›å¼åŠ è½½ï¼‰
        """
        messages = []

        # ç³»ç»Ÿæç¤ºè¯
        system_prompt = await self._prompt_service.get_content("system.chat")
        if system_prompt:
            messages.append(SystemMessage(content=system_prompt))

        # æ³¨å…¥åŒ¹é…çš„ Skill å†…å®¹ï¼ˆæ¸è¿›å¼åŠ è½½çš„æ ¸å¿ƒï¼‰
        if skill_context:
            messages.append(SystemMessage(content=skill_context))

        # å†å²æ¶ˆæ¯
        history = await self._conversation_service.get_messages(conversation_id)
        for msg in history:
            if msg.role.value == "user":
                messages.append(HumanMessage(content=msg.content))
            elif msg.role.value == "assistant":
                messages.append(AIMessage(content=msg.content))

        # å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append(HumanMessage(content=user_message))

        return messages

    async def chat_stream(
        self,
        message: str,
        conversation_id: str | None = None,
    ) -> AsyncGenerator[StreamEvent, None]:
        """æµå¼èŠå¤© - å§”æ‰˜ç»™çŠ¶æ€æœºé©±åŠ¨çš„ Agent æ¨¡å¼"""
        async for event in self.chat_stream_with_tools(message, conversation_id):
            yield event

    async def chat_stream_with_tools(
        self,
        message: str,
        conversation_id: str | None = None,
    ) -> AsyncGenerator[StreamEvent, None]:
        """æµå¼èŠå¤© - ä½¿ç”¨ LangGraph Agent
        
        ä½¿ç”¨ create_agent + agent.astream å¤„ç†æ¶ˆæ¯æµï¼Œ
        å·¥å…·è°ƒç”¨ç”± LangGraph å†…éƒ¨å¤„ç†ã€‚
        """
        seq = 0

        def next_seq() -> int:
            nonlocal seq
            seq += 1
            return seq

        # åˆ›å»ºæˆ–è·å–ä¼šè¯
        if conversation_id:
            conversation = await self._conversation_service.get_conversation(
                conversation_id
            )
            if not conversation:
                conversation = await self._conversation_service.create_conversation()
                conversation_id = conversation.id
        else:
            conversation = await self._conversation_service.create_conversation()
            conversation_id = conversation.id

        user_message_id = str(uuid.uuid4())
        assistant_message_id = str(uuid.uuid4())

        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        await self._conversation_service.add_message(
            conversation_id=conversation_id,
            role="user",
            content=message,
            message_id=user_message_id,
        )

        # å‘é€å¼€å§‹äº‹ä»¶
        yield make_event(
            seq=next_seq(),
            type=StreamEventType.META_START.value,
            conversation_id=conversation_id,
            message_id=assistant_message_id,
            payload={
                "user_message_id": user_message_id,
                "assistant_message_id": assistant_message_id,
                "mode": "agent",
            },
        )

        try:
            start_time = time.time()

            # è·å– LLM
            llm = await self._get_llm()

            # è·å–ç³»ç»Ÿæç¤ºè¯
            system_prompt = await self._prompt_service.get_content("system.chat") or ""

            # ä½¿ç”¨ SDK çš„ QueueDomainEmitter
            loop = asyncio.get_running_loop()
            domain_queue: asyncio.Queue[dict[str, Any]] = asyncio.Queue(maxsize=10000)
            emitter = QueueDomainEmitter(queue=domain_queue, loop=loop)

            # åˆ›å»ºä¸Šä¸‹æ–‡
            context = ChatContext(
                emitter=emitter,
                conversation_id=conversation_id,
                user_id="default_user",
                assistant_message_id=assistant_message_id,
                db=self._session,
            )

            # è·å– Agent
            agent = await agent_service.get_agent(
                model=llm,
                system_prompt=system_prompt,
                session=self._session,
                emitter=emitter,
            )

            # ä½¿ç”¨ SDK æµå“åº”å¤„ç†å™¨
            handler = StreamingResponseHandler(
                emitter=emitter,
                conversation_id=conversation_id,
            )

            # å‡†å¤‡ Agent è¾“å…¥
            agent_input = {"messages": [HumanMessage(content=message)]}
            agent_config: dict[str, Any] = {"configurable": {"thread_id": conversation_id}}

            full_content = ""

            # åˆ›å»º Agent æµä»»åŠ¡
            async def run_agent_stream():
                stream_item_count = 0
                try:
                    async for item in agent.astream(
                        agent_input,
                        config=agent_config,
                        context=context,
                        stream_mode="messages",
                    ):
                        stream_item_count += 1
                        msg = item[0] if isinstance(item, (tuple, list)) and item else item
                        logger.info(f"ğŸ”„ æµæ¶ˆæ¯ #{stream_item_count}: type={type(msg).__name__}")
                        await handler.handle_message(msg)
                    
                    logger.info(f"âœ… æµå¤„ç†å®Œæˆ, å…± {stream_item_count} æ¡æ¶ˆæ¯")
                    await handler.finalize()
                finally:
                    # å‘é€ç»“æŸæ ‡è®°
                    await domain_queue.put({"type": "__end__", "payload": None})

            # å¯åŠ¨ Agent æµä»»åŠ¡
            producer_task = asyncio.create_task(run_agent_stream())

            # ä»é˜Ÿåˆ—æ¶ˆè´¹äº‹ä»¶å¹¶ yield
            while True:
                evt = await domain_queue.get()
                evt_type = evt.get("type")
                if evt_type == "__end__":
                    break

                payload = evt.get("payload", {})
                
                # æ”¶é›†æœ€ç»ˆå†…å®¹
                if evt_type == StreamEventType.ASSISTANT_DELTA.value:
                    delta = payload.get("delta", "")
                    if delta:
                        full_content += delta
                elif evt_type == StreamEventType.ASSISTANT_FINAL.value:
                    full_content = payload.get("content") or full_content

                yield make_event(
                    seq=next_seq(),
                    conversation_id=conversation_id,
                    message_id=assistant_message_id,
                    type=evt_type,
                    payload=payload,
                )

            await producer_task

            elapsed_ms = int((time.time() - start_time) * 1000)

            # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
            await self._conversation_service.add_message(
                conversation_id=conversation_id,
                role="assistant",
                content=full_content,
                message_id=assistant_message_id,
                latency_ms=elapsed_ms,
            )

        except Exception as e:
            logger.exception("Agent èŠå¤©å¤±è´¥", conversation_id=conversation_id, error=str(e))
            yield make_event(
                seq=next_seq(),
                type=StreamEventType.ERROR.value,
                conversation_id=conversation_id,
                message_id=assistant_message_id,
                payload={"message": str(e)},
            )

    async def chat(self, message: str, conversation_id: str | None = None) -> dict:
        """éæµå¼èŠå¤©"""
        result = {
            "conversation_id": "",
            "message_id": "",
            "content": "",
        }

        async for event in self.chat_stream(message, conversation_id):
            if event.type == StreamEventType.META_START.value:
                result["conversation_id"] = event.conversation_id
                result["message_id"] = event.message_id
            elif event.type == StreamEventType.ASSISTANT_DELTA.value:
                result["content"] += event.payload.get("delta", "")
            elif event.type == StreamEventType.ERROR.value:
                raise Exception(event.payload.get("message", "Unknown error"))

        return result
