"""æµå“åº”å¤„ç†å™¨ - è§£æ Agent æµè¾“å‡ºï¼Œå‘å°„äº‹ä»¶

ä½¿ç”¨æ–¹å¼ï¼š
    from app.services.agent.streams import StreamingResponseHandler

    # ä¼ å…¥ modelï¼Œè‡ªåŠ¨æ£€æµ‹ç‰ˆæœ¬
    handler = StreamingResponseHandler(emitter=context.emitter, model=model)

    async for msg in agent.astream(...):
        await handler.handle_message(msg)
    result = await handler.finalize()

èŒè´£ï¼š
    1. è§£æ AIMessageChunk/AIMessage/ToolMessage
    2. æŒ‰å—ç±»å‹åˆ†æµï¼štext â†’ æ­£æ–‡å¢é‡ï¼Œreasoning â†’ æ¨ç†å¢é‡
    3. å‘å°„å¯¹åº”çš„äº‹ä»¶åˆ° emitter
    4. æ±‡æ€»æœ€ç»ˆç»“æœ

ç‰ˆæœ¬è‡ªåŠ¨æ£€æµ‹ï¼š
    - æ ¹æ® model çš„ _chat_model_version å±æ€§è‡ªåŠ¨åˆ¤æ–­
    - v1 æ¨¡å‹ï¼šä½¿ç”¨ parse_content_blocks() ä» content_blocks æå–
    - v0 æ¨¡å‹ï¼šä½¿ç”¨ model.extract_reasoning() ä»è‡ªå®šä¹‰å±æ€§æå–
    - æ—  model æ—¶é»˜è®¤ä½¿ç”¨ v1
"""

import json
from dataclasses import dataclass, field
from typing import Any

from langchain_core.messages import AIMessage, AIMessageChunk, ToolMessage

from app.core.logging import get_logger
from app.schemas.events import StreamEventType

logger = get_logger("streams.handler")


@dataclass
class StreamingResponseHandler:
    """æµå“åº”å¤„ç†å™¨ï¼ˆæ ¹æ® model è‡ªåŠ¨æ£€æµ‹ç‰ˆæœ¬ï¼‰

    Attributes:
        emitter: äº‹ä»¶å‘å°„å™¨ï¼ˆéœ€è¦æœ‰ aemit æ–¹æ³•ï¼‰
        model: LLM æ¨¡å‹å®ä¾‹ï¼ˆç”¨äºç‰ˆæœ¬æ£€æµ‹å’Œ v0 æ¨¡å¼çš„ extract_reasoningï¼‰
        conversation_id: ä¼šè¯ IDï¼ˆç”¨äºæ—¥å¿—ï¼‰
    """

    emitter: Any
    model: Any = None
    conversation_id: str = ""

    # å†…éƒ¨çŠ¶æ€
    full_content: str = field(default="", init=False)
    full_reasoning: str = field(default="", init=False)
    seen_tool_ids: set[str] = field(default_factory=set, init=False)

    # ç»Ÿè®¡
    content_events: int = field(default=0, init=False)
    reasoning_events: int = field(default=0, init=False)
    reasoning_chars: int = field(default=0, init=False)

    async def handle_message(self, msg: Any) -> None:
        """å¤„ç†å•æ¡æ¶ˆæ¯ï¼ˆæ ¸å¿ƒåˆ†å‘é€»è¾‘ï¼‰

        Args:
            msg: LangChain æ¶ˆæ¯å¯¹è±¡
        """
        # è°ƒè¯•ï¼šè®°å½•æ”¶åˆ°çš„æ¶ˆæ¯ç±»å‹ï¼ˆä¸´æ—¶ä½¿ç”¨ info çº§åˆ«ä¾¿äºè°ƒè¯•ï¼‰
        msg_type = type(msg).__name__
        content_preview = getattr(msg, 'content', None)
        if content_preview and isinstance(content_preview, str):
            content_preview = content_preview[:100]
        elif content_preview and isinstance(content_preview, list):
            content_preview = f"list[{len(content_preview)}]"
        logger.info(f"ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯: type={msg_type}, content={content_preview}")
        
        if isinstance(msg, AIMessageChunk):
            await self._handle_ai_chunk(msg)
        elif isinstance(msg, AIMessage):
            await self._handle_ai_message(msg)
        elif isinstance(msg, ToolMessage):
            await self._handle_tool_message(msg)
        else:
            logger.debug(f"âš ï¸ æœªå¤„ç†çš„æ¶ˆæ¯ç±»å‹: {msg_type}")

    def _is_v1_model(self) -> bool:
        """æ£€æµ‹æ˜¯å¦ä½¿ç”¨ v1 æ¨¡å¼"""
        from app.core.chat_models import is_v1_model
        return is_v1_model(self.model)

    async def _handle_ai_chunk(self, msg: AIMessageChunk) -> None:
        """å¤„ç† AI å¢é‡æ¶ˆæ¯"""
        is_v1 = self._is_v1_model()
        logger.info(f"ğŸ” æ¨¡å‹ç‰ˆæœ¬æ£€æµ‹: is_v1={is_v1}, model_type={type(self.model).__name__}")
        if is_v1:
            await self._handle_ai_chunk_v1(msg)
        else:
            await self._handle_ai_chunk_v0(msg)

    async def _handle_ai_chunk_v1(self, msg: AIMessageChunk) -> None:
        """v1ï¼šä½¿ç”¨ content_blocks è§£æ"""
        from app.core.chat_models import parse_content_blocks

        parsed = parse_content_blocks(msg)

        # æ–‡æœ¬å¢é‡
        text_delta = parsed.text
        if text_delta:
            self.full_content += text_delta
            self.content_events += 1
            # è®°å½•æµè¾“å‡ºï¼ˆä»…å‰100å­—ç¬¦ï¼Œé¿å…æ—¥å¿—è¿‡é•¿ï¼‰
            if self.content_events <= 3 or self.content_events % 10 == 0:
                logger.debug(f"ğŸ“ æµè¾“å‡º #{self.content_events}: {text_delta[:100]}..." if len(text_delta) > 100 else f"ğŸ“ æµè¾“å‡º #{self.content_events}: {text_delta}")
            await self.emitter.aemit(
                StreamEventType.ASSISTANT_DELTA.value,
                {"delta": text_delta},
            )

        # æ¨ç†å¢é‡
        reasoning_delta = parsed.reasoning
        if reasoning_delta:
            self.full_reasoning += reasoning_delta
            self.reasoning_chars += len(reasoning_delta)
            self.reasoning_events += 1
            await self.emitter.aemit(
                StreamEventType.ASSISTANT_REASONING_DELTA.value,
                {"delta": reasoning_delta},
            )

    async def _handle_ai_chunk_v0(self, msg: AIMessageChunk) -> None:
        """v0ï¼šä½¿ç”¨ model.extract_reasoning() è§£æ"""
        # æ­£æ–‡å¢é‡
        delta = msg.content or ""
        logger.info(f"ğŸ”§ v0å¤„ç†: deltaç±»å‹={type(delta).__name__}, å†…å®¹={delta[:50] if isinstance(delta, str) else delta}")
        if isinstance(delta, list):
            delta = "".join(str(x) for x in delta)
        if isinstance(delta, str) and delta:
            self.full_content += delta
            self.content_events += 1
            # è®°å½•æµè¾“å‡º
            logger.info(f"ğŸ“ å‘é€delta #{self.content_events}: {delta[:50]}...")
            await self.emitter.aemit(
                StreamEventType.ASSISTANT_DELTA.value,
                {"delta": delta},
            )

        # æ¨ç†å¢é‡ï¼ˆé€šè¿‡å¤šæ€æ¥å£æå–ï¼‰
        if self.model and hasattr(self.model, "extract_reasoning"):
            reasoning_chunk = self.model.extract_reasoning(msg)
            if reasoning_chunk and reasoning_chunk.delta:
                self.full_reasoning += reasoning_chunk.delta
                self.reasoning_chars += len(reasoning_chunk.delta)
                self.reasoning_events += 1
                await self.emitter.aemit(
                    StreamEventType.ASSISTANT_REASONING_DELTA.value,
                    {"delta": reasoning_chunk.delta},
                )

    async def _handle_ai_message(self, msg: AIMessage) -> None:
        """å¤„ç†å®Œæ•´ AI æ¶ˆæ¯ï¼ˆå…œåº•åœºæ™¯ï¼‰"""
        if self._is_v1_model():
            await self._handle_ai_message_v1(msg)
        else:
            await self._handle_ai_message_v0(msg)

    async def _handle_ai_message_v1(self, msg: AIMessage) -> None:
        """v1ï¼šä½¿ç”¨ content_blocks è§£æï¼ˆå…œåº•ï¼‰"""
        from app.core.chat_models import parse_content_blocks

        parsed = parse_content_blocks(msg)

        # å…œåº•ï¼šå¦‚æœä¹‹å‰æ²¡æœ‰æ”¶åˆ°ä»»ä½• content chunk
        if self.content_events == 0:
            text_delta = parsed.text
            if text_delta:
                self.full_content += text_delta
                self.content_events += 1
                await self.emitter.aemit(
                    StreamEventType.ASSISTANT_DELTA.value,
                    {"delta": text_delta},
                )

        # å…œåº•ï¼šä»å®Œæ•´ AIMessage æå–æ¨ç†
        if self.reasoning_events == 0:
            reasoning_delta = parsed.reasoning
            if reasoning_delta:
                self.full_reasoning += reasoning_delta
                self.reasoning_chars += len(reasoning_delta)
                self.reasoning_events += 1
                await self.emitter.aemit(
                    StreamEventType.ASSISTANT_REASONING_DELTA.value,
                    {"delta": reasoning_delta},
                )

    async def _handle_ai_message_v0(self, msg: AIMessage) -> None:
        """v0ï¼šä½¿ç”¨ model.extract_reasoning() è§£æï¼ˆå…œåº•ï¼‰"""
        # å…œåº•ï¼šå¦‚æœä¹‹å‰æ²¡æœ‰æ”¶åˆ°ä»»ä½• content chunk
        if self.content_events == 0:
            delta = msg.content or ""
            if isinstance(delta, list):
                delta = "".join(str(x) for x in delta)
            if isinstance(delta, str) and delta:
                self.full_content += delta
                self.content_events += 1
                await self.emitter.aemit(
                    StreamEventType.ASSISTANT_DELTA.value,
                    {"delta": delta},
                )

        # å…œåº•ï¼šä»å®Œæ•´ AIMessage æå–æ¨ç†
        if self.reasoning_events == 0 and self.model and hasattr(self.model, "extract_reasoning"):
            reasoning_chunk = self.model.extract_reasoning(msg)
            if reasoning_chunk and reasoning_chunk.delta:
                self.full_reasoning += reasoning_chunk.delta
                self.reasoning_chars += len(reasoning_chunk.delta)
                self.reasoning_events += 1
                await self.emitter.aemit(
                    StreamEventType.ASSISTANT_REASONING_DELTA.value,
                    {"delta": reasoning_chunk.delta},
                )

    async def _handle_tool_message(self, msg: ToolMessage) -> None:
        """å¤„ç†å·¥å…·æ¶ˆæ¯"""
        # å»é‡
        msg_id = getattr(msg, "id", None)
        if isinstance(msg_id, str) and msg_id in self.seen_tool_ids:
            return
        if isinstance(msg_id, str):
            self.seen_tool_ids.add(msg_id)

        content = msg.content
        try:
            parsed_data: Any
            if isinstance(content, str):
                parsed_data = json.loads(content)
            elif isinstance(content, (list, dict)):
                parsed_data = content
            else:
                return
        except Exception:
            pass

    async def finalize(self) -> dict[str, Any]:
        """å‘é€æœ€ç»ˆäº‹ä»¶ï¼Œè¿”å›æ±‡æ€»æ•°æ®

        Returns:
            åŒ…å« contentã€reasoning çš„å­—å…¸
        """
        # å…œåº•ï¼šä»…å½“"å…¨ç¨‹æ²¡æœ‰ä»»ä½• content delta"æ—¶ï¼Œæ‰æŠŠ reasoning å…œåº•æˆ contentï¼ˆé¿å…æ··æµï¼‰
        if self.content_events == 0 and self.full_reasoning.strip():
            logger.warning(
                "æ£€æµ‹åˆ° content å…¨ç¨‹ä¸ºç©ºï¼Œå…œåº•å°† reasoning ä½œä¸º content è¾“å‡º",
                conversation_id=self.conversation_id,
                content_len=len(self.full_content),
                reasoning_len=len(self.full_reasoning),
            )
            self.full_content = self.full_reasoning
            self.full_reasoning = ""

        result = {
            "content": self.full_content,
            "reasoning": self.full_reasoning if self.full_reasoning else None,
        }

        await self.emitter.aemit(StreamEventType.ASSISTANT_FINAL.value, result)

        logger.info(
            "âœ… æµå¤„ç†å®Œæˆ",
            conversation_id=self.conversation_id,
            content_events=self.content_events,
            reasoning_events=self.reasoning_events,
            reasoning_chars=self.reasoning_chars,
        )

        return result

    def get_stats(self) -> dict[str, int]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡å­—å…¸
        """
        return {
            "content_events": self.content_events,
            "reasoning_events": self.reasoning_events,
            "reasoning_chars": self.reasoning_chars,
        }
