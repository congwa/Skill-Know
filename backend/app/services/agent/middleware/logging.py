"""æ—¥å¿—ä¸­é—´ä»¶

è´Ÿè´£è®°å½•æ¯æ¬¡ LLM è°ƒç”¨çš„å®Œæ•´è¾“å…¥è¾“å‡ºã€‚
ä¸ embedease-ai ä¿æŒä¸€è‡´ã€‚
"""

import time
import uuid
from collections.abc import Awaitable, Callable
from typing import Any

from langchain.agents.middleware.types import AgentMiddleware, ModelRequest, ModelResponse
from langchain_core.messages import BaseMessage

from app.core.logging import get_logger

logger = get_logger("middleware.llm")


def _truncate_text(value: Any, *, limit: int = 500) -> str | None:
    if value is None:
        return None
    text = str(value)
    if len(text) <= limit:
        return text
    return text[:limit] + "..."


def _summarize_tool_calls(tool_calls: Any) -> dict[str, Any] | None:
    """å°† tool_calls å‹ç¼©æˆå¯è¯»æ‘˜è¦"""
    if not tool_calls:
        return None

    if isinstance(tool_calls, list):
        items: list[dict[str, Any]] = []
        for tc in tool_calls[:10]:
            item: dict[str, Any] = {}
            if isinstance(tc, dict):
                item["id"] = str(tc.get("id")) if tc.get("id") is not None else None
                item["name"] = str(tc.get("name")) if tc.get("name") is not None else None
                args = tc.get("args")
                if isinstance(args, dict):
                    item["args_keys"] = sorted(list(args.keys()))[:20]
            elif hasattr(tc, "id") or hasattr(tc, "name"):
                item["id"] = str(getattr(tc, "id", None))
                item["name"] = str(getattr(tc, "name", None))
                args = getattr(tc, "args", None)
                if isinstance(args, dict):
                    item["args_keys"] = sorted(list(args.keys()))[:20]
            items.append(item)
        return {"count": len(tool_calls), "items": items}
    return {"type": str(type(tool_calls).__name__)}


def _serialize_message(msg: BaseMessage) -> dict[str, Any]:
    """åºåˆ—åŒ–æ¶ˆæ¯ç”¨äºæ—¥å¿—"""
    content = getattr(msg, "content", None)
    content_text = content if isinstance(content, str) else str(content) if content is not None else ""
    
    return {
        "type": type(msg).__name__,
        "content": _truncate_text(content, limit=1200),
        "content_length": len(content_text) if content_text else 0,
        "tool_calls": _summarize_tool_calls(getattr(msg, "tool_calls", None)),
    }


def _serialize_messages(messages: list) -> list[dict[str, Any]]:
    """åºåˆ—åŒ–æ¶ˆæ¯åˆ—è¡¨"""
    return [_serialize_message(m) for m in messages if isinstance(m, BaseMessage)]


def _serialize_tool(tool: Any) -> dict[str, Any]:
    """åºåˆ—åŒ–å·¥å…·ä¿¡æ¯"""
    if isinstance(tool, dict):
        name = tool.get("name") or tool.get("function", {}).get("name") or tool.get("id")
        return {"type": "provider_dict", "name": name}
    return {
        "type": type(tool).__name__,
        "name": getattr(tool, "name", None),
        "description": _truncate_text(getattr(tool, "description", None), limit=200),
    }


class LoggingMiddleware(AgentMiddleware):
    """æ—¥å¿—ä¸­é—´ä»¶
    
    è®°å½•æ¯æ¬¡ LLM è°ƒç”¨çš„è¾“å…¥è¾“å‡ºã€å·¥å…·åˆ—è¡¨ã€è°ƒç”¨è€—æ—¶ç­‰ä¿¡æ¯ã€‚
    åŒæ—¶å‘é€ llm.call.start å’Œ llm.call.end äº‹ä»¶åˆ°å‰ç«¯ã€‚
    """
    
    def __init__(self, emitter: Any = None):
        super().__init__()
        self._emitter = emitter

    async def awrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], Awaitable[ModelResponse]],
    ) -> ModelResponse:
        """è®°å½• LLM è°ƒç”¨çš„è¾“å…¥è¾“å‡º"""
        from app.schemas.events import StreamEventType
        
        start_time = time.time()
        llm_call_id = uuid.uuid4().hex

        # æ„å»ºæœ‰æ•ˆæ¶ˆæ¯åˆ—è¡¨
        effective_messages: list[Any] = list(request.messages)
        if request.system_message is not None:
            effective_messages = [request.system_message, *effective_messages]

        # è®°å½•è¯·æ±‚ä¿¡æ¯
        request_data = {
            "llm_call_id": llm_call_id,
            "message_count": len(effective_messages),
            "tools": [_serialize_tool(t) for t in request.tools],
            "tool_count": len(request.tools),
            "tool_choice": request.tool_choice,
        }

        logger.info("ğŸš€ LLM è°ƒç”¨å¼€å§‹", **request_data)
        
        # å‘é€ llm.call.start äº‹ä»¶åˆ°å‰ç«¯
        if self._emitter and hasattr(self._emitter, "aemit"):
            await self._emitter.aemit(
                StreamEventType.LLM_CALL_START.value,
                {
                    "llm_call_id": llm_call_id,
                    "message_count": len(effective_messages),
                },
            )

        try:
            response = await handler(request)
            elapsed_ms = int((time.time() - start_time) * 1000)

            # è®°å½•å“åº”ä¿¡æ¯
            response_data = {
                "llm_call_id": llm_call_id,
                "messages": _serialize_messages(response.result),
                "message_count": len(response.result),
                "elapsed_ms": elapsed_ms,
            }

            logger.info("âœ… LLM è°ƒç”¨å®Œæˆ", **response_data)
            
            # å‘é€ llm.call.end äº‹ä»¶åˆ°å‰ç«¯
            if self._emitter and hasattr(self._emitter, "aemit"):
                await self._emitter.aemit(
                    StreamEventType.LLM_CALL_END.value,
                    {
                        "llm_call_id": llm_call_id,
                        "elapsed_ms": elapsed_ms,
                    },
                )
            
            return response

        except Exception as e:
            elapsed_ms = int((time.time() - start_time) * 1000)
            logger.error(
                "âŒ LLM è°ƒç”¨å¤±è´¥",
                llm_call_id=llm_call_id,
                error=str(e),
                error_type=type(e).__name__,
                elapsed_ms=elapsed_ms,
                exc_info=True,
            )
            
            # å‘é€é”™è¯¯äº‹ä»¶
            if self._emitter and hasattr(self._emitter, "aemit"):
                await self._emitter.aemit(
                    StreamEventType.LLM_CALL_END.value,
                    {
                        "llm_call_id": llm_call_id,
                        "elapsed_ms": elapsed_ms,
                        "error": str(e),
                    },
                )
            
            raise
